{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ijimin/miniforge3/envs/proj_24_2/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Loss: 0.6553, Test Acc: 0.6953\n",
      "Epoch 002, Loss: 0.4010, Test Acc: 0.6342\n",
      "Epoch 003, Loss: 0.3109, Test Acc: 0.7401\n",
      "Epoch 004, Loss: 0.2771, Test Acc: 0.7905\n",
      "Epoch 005, Loss: 0.2508, Test Acc: 0.7678\n",
      "Epoch 006, Loss: 0.2441, Test Acc: 0.8118\n",
      "Epoch 007, Loss: 0.2348, Test Acc: 0.7983\n",
      "Epoch 008, Loss: 0.2224, Test Acc: 0.8111\n",
      "Epoch 009, Loss: 0.2239, Test Acc: 0.7905\n",
      "Epoch 010, Loss: 0.2095, Test Acc: 0.8359\n",
      "Epoch 011, Loss: 0.2096, Test Acc: 0.8594\n",
      "Epoch 012, Loss: 0.1939, Test Acc: 0.8722\n",
      "Epoch 013, Loss: 0.1955, Test Acc: 0.8551\n",
      "Epoch 014, Loss: 0.1862, Test Acc: 0.8786\n",
      "Epoch 015, Loss: 0.1786, Test Acc: 0.8828\n",
      "Epoch 016, Loss: 0.1779, Test Acc: 0.8679\n",
      "Epoch 017, Loss: 0.1689, Test Acc: 0.8821\n",
      "Epoch 018, Loss: 0.1594, Test Acc: 0.8821\n",
      "Epoch 019, Loss: 0.1671, Test Acc: 0.8587\n",
      "Epoch 020, Loss: 0.1548, Test Acc: 0.9027\n",
      "Epoch 021, Loss: 0.1542, Test Acc: 0.8700\n",
      "Epoch 022, Loss: 0.1538, Test Acc: 0.8892\n",
      "Epoch 023, Loss: 0.1524, Test Acc: 0.8970\n",
      "Epoch 024, Loss: 0.1466, Test Acc: 0.8487\n"
     ]
    }
   ],
   "source": [
    "# requirements: numpy, pandas, torch, torch_geometric, scikit-learn\n",
    "import torch\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('data.csv')\n",
    "X = df.iloc[:, :-1].values  # 마지막 컬럼 제외한 모든 컬럼\n",
    "y = df.iloc[:, -1].values   # 마지막 컬럼 (클래스)\n",
    "\n",
    "# 클래스 레이블을 숫자로 변환\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# 데이터를 그래프 형태로 변환\n",
    "def create_graph_data(x, y):\n",
    "    # 랜드마크 간의 연결 관계 정의 (MediaPipe 포즈 연결)\n",
    "    edges = [\n",
    "        # 얼굴 연결\n",
    "        (0, 1), (1, 2), (2, 3), (3, 4),  # 코\n",
    "        (5, 6), (6, 7), (7, 8), (8, 9),  # 왼쪽 눈\n",
    "        (10, 11), (11, 12), (12, 13), (13, 14),  # 오른쪽 눈\n",
    "        # 몸통 연결\n",
    "        (11, 12), (11, 23), (12, 24),  # 어깨\n",
    "        (23, 24), (23, 25), (24, 26),  # 엉덩이\n",
    "        (25, 27), (26, 28),  # 무릎\n",
    "        #(27, 29), (28, 30),  # 발목\n",
    "        #(29, 31), (30, 32)   # 발\n",
    "    ]\n",
    "    \n",
    "    # 양방향 연결 추가\n",
    "    edges = edges + [(j, i) for i, j in edges]\n",
    "    \n",
    "    # 노드 특성 (x, y, z, visibility)\n",
    "    node_features = x.reshape(-1, 4)\n",
    "    \n",
    "    # 엣지 인덱스 생성\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    return Data(x=torch.tensor(node_features, dtype=torch.float),\n",
    "                edge_index=edge_index,\n",
    "                y=torch.tensor([y], dtype=torch.long))\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = [create_graph_data(X[i], y[i]) for i in range(len(X))]\n",
    "\n",
    "# GCN 모델 정의\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "        self.dropout = Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)\n",
    "    \n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction='none')  # [B]\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# 학습 함수\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y.squeeze()).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 분할\n",
    "train_idx, test_idx = train_test_split(range(len(dataset)), test_size=0.2, stratify=y)\n",
    "train_dataset = [dataset[i] for i in train_idx]\n",
    "test_dataset = [dataset[i] for i in test_idx]\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# 모델 초기화 및 학습\n",
    "model = GCN(in_channels=4, hidden_channels=64, num_classes=len(np.unique(y)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = FocalLoss(alpha=1.0, gamma=2.0)\n",
    "\n",
    "for epoch in range(1, 25):\n",
    "    loss = train(model, train_loader, optimizer, criterion)\n",
    "    acc = evaluate(model, test_loader)\n",
    "    print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'gcn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_24_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
